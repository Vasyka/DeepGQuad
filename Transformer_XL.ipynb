{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "LkyhP9gPP6uM",
    "outputId": "2418abae-6cb6-482a-c2dd-5a4985545fe8"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "id": "q2Nr6zGBFECW",
    "outputId": "ab587de5-506d-446c-ae78-e37f98ff1853"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1225377879585711517, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14843097310175648441\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 4551530376532886185\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15701401920\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 643053043211529335\n",
       " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "qZ2aUnkDRVOd",
    "outputId": "cf6f5a3c-7a10-4d5e-e582-f5f7a269c8aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/DeepGQuad/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-04112792c13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/DeepGQuad/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/DeepGQuad/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "path = '/content/drive/My Drive/DeepGQuad/'\n",
    "os.chdir(path)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "SCM5dAoCzObB",
    "outputId": "80ea9927-73a7-4f2c-eae4-8fcfd76f1e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 26 13:21:01 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "WYkngo-tRoHw",
    "outputId": "15a2952d-543e-4ace-c813-aa23aa4bb32d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>713977</td>\n",
       "      <td>714310</td>\n",
       "      <td>ACCATGGCGCCCCAGTGATGTAGCCGAACACCCGCGCCTCTAACGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>762850</td>\n",
       "      <td>762982</td>\n",
       "      <td>GGAGGGCACTCACCCGAGCGGACCTTGGCTCCGGATAATCCGTTTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>840076</td>\n",
       "      <td>840205</td>\n",
       "      <td>gccgcctccgaacgtggccgccgcctcctccgaacgtggccgcttc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>894635</td>\n",
       "      <td>894796</td>\n",
       "      <td>CGTGCACCCCACTTCCGGCCCCAGAATGCCGCGCGGCTGCGCACTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>935414</td>\n",
       "      <td>935699</td>\n",
       "      <td>GCGGGCGAGCGGCGAGCGCGCGGCGATCCGAGCCCCTAGGGCGGAT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chr   start     end                                                seq\n",
       "0  chr1  713977  714310  ACCATGGCGCCCCAGTGATGTAGCCGAACACCCGCGCCTCTAACGT...\n",
       "1  chr1  762850  762982  GGAGGGCACTCACCCGAGCGGACCTTGGCTCCGGATAATCCGTTTC...\n",
       "2  chr1  840076  840205  gccgcctccgaacgtggccgccgcctcctccgaacgtggccgcttc...\n",
       "3  chr1  894635  894796  CGTGCACCCCACTTCCGGCCCCAGAATGCCGCGCGGCTGCGCACTT...\n",
       "4  chr1  935414  935699  GCGGGCGAGCGGCGAGCGCGCGGCGATCCGAGCCCCTAGGGCGGAT..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['chr','start','end','seq']\n",
    "df = pd.read_csv(f'./Data/chr1.bed',sep='\\t',header=None)\n",
    "df.columns = columns\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fS4nhEfv7Ez"
   },
   "outputs": [],
   "source": [
    "# Load first chromosome data\n",
    "with open('Data/chr1.fa') as f:\n",
    "  seq = f.read()\n",
    "seq = seq[6:]\n",
    "seq = seq.replace('\\n','')\n",
    "seq = seq.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m-bzZHK3riN0",
    "outputId": "d3db11e7-4ff2-42c6-f5f8-ffa71efe39ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249250621"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sequnce regione\n",
    "print(len(seq))\n",
    "start = 700000#10000\n",
    "end = 3700000\n",
    "s = seq[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m8taMwXCxraT",
    "outputId": "7ce42498-e1b7-48ae-9d30-5ff02825c500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Tokenize nucleotids\n",
    "s_encoded = np.zeros([len(s),3],dtype=np.int8)\n",
    "dna_dict = {'a':0, 't':1,'c':2, 'g':3, 'n':np.random.randint(0,4)}\n",
    "for i, nucl in enumerate(s):\n",
    "  if i % 1000000 ==0:\n",
    "    print(i)\n",
    "  s_encoded[i,0] = dna_dict[nucl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "q9QYc5Ub4kaB",
    "outputId": "be29b7a8-6fc3-4fcf-8bbb-51b10a3ee483"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label data\n",
    "count = 0\n",
    "for i, row in df.iterrows():\n",
    "  if row.chr == 'chr1':\n",
    "    if start < row.start and row.end < end:\n",
    "      count+=1\n",
    "      s_encoded[row.start:row.end,1:] = [1,1]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTuJrPMEHa6G"
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./Data/g4_quad/g4quad_1.npz',s_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfL9SroUA7Y6"
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./Data/g4_quad/g4quad_small.npz',s_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nw12Jq0w4yIx"
   },
   "outputs": [],
   "source": [
    "s_encoded = np.load('./Data/g4_quad/g4quad_1.npz',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qi1R2JQsJtM1"
   },
   "outputs": [],
   "source": [
    "#!python scripts/eval_transformer_xl.py --model_path output/-g4quad_1.npz/20200526-113720/model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wz7zEZhuwJKm"
   },
   "outputs": [],
   "source": [
    "#!chmod +x scripts/run_trasformer_xl.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BzVA1pW7c5MB",
    "outputId": "0ab63013-b35d-4590-db21-a0eedd434a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run training...\n",
      "data/g4_quad/g4quad_1.npz\n",
      "Namespace(adaptive=False, batch_chunk=1, batch_size=10, clamp_len=-1, clip=0.25, clip_nonemb=False, conv_emb=False, conv_size=7, cuda=True, d_embed=32, d_head=32, d_inner=256, d_model=32, data_path='data/g4_quad/g4quad_1.npz', debug=False, decay_rate=0.5, dropatt=0.0, dropout=0.1, emb_init='normal', emb_init_range=0.01, emb_path=None, eta_min=0.0, eval_interval=3000, eval_tgt_len=512, ext_ds=0, gpu0_bsz=0, init='normal', init_range=0.1, init_std=0.02, log_interval=200, lr=0.0001, lr_min=0.0, max_eval_steps=-1, max_step=85000, mem_len=0, methylation=False, multi_gpu=False, n_head=6, n_layer=6, not_tied=True, optim='adam', optim_type=0, output_path='output/', patience=0, pre_conv=False, proj_init_std=0.01, restart=False, restart_dir='', same_length=False, scheduler='cosine', seed=2222, shift=20, tgt_len=512, varlen=True, warmup_step=3000)\n",
      "WARNING: Labels are shifted by 20\n",
      "Full dataset size: 990000\n",
      "Train set size: 1386000\n",
      "Test set size: 396000\n",
      "building vocab with min_freq=0, max_size=None\n",
      "final vocab size 4 from 4 unique tokens\n",
      "Train set: 297000-990000\t Test set: 0-198000\t Valid set: 198000-297000\n",
      "Working directory : output/-g4quad_1.npz/20200526-113720\n",
      "FocalLoss(gamma=1, alpha=None)\n",
      "| epoch   1 step      200 |    200 batches | lr 6.67e-06 | ms/batch 718.55 | loss 0.378644 | bpc   0.54627\n",
      "[[0.4885966784093515, 0.48859668143526913]] [[0.9958542792047437, 0.003952481760166135]]\n",
      "| epoch   2 step      400 |    123 batches | lr 1.33e-05 | ms/batch 757.94 | loss 0.272170 | bpc   0.39266\n",
      "[[0.5023651089442369, 0.5023651026950591]] [[0.9959650925339333, 0.004112361773541117]]\n",
      "| epoch   3 step      600 |     47 batches | lr 2e-05 | ms/batch 764.10 | loss 0.117299 | bpc   0.16923\n",
      "| epoch   3 step      800 |    247 batches | lr 2.67e-05 | ms/batch 713.29 | loss 0.063066 | bpc   0.09099\n",
      "[[0.5031780734264453, 0.503178074676281]] [[0.9959340009743713, 0.004067542028624417]]\n",
      "| epoch   4 step     1000 |    169 batches | lr 3.33e-05 | ms/batch 738.40 | loss 0.039101 | bpc   0.05641\n",
      "[[0.4990054427659777, 0.4990054384244437]] [[0.9958988143289833, 0.004026065552493596]]\n",
      "| epoch   5 step     1200 |     90 batches | lr 4e-05 | ms/batch 732.49 | loss 0.028049 | bpc   0.04047\n",
      "[[0.49927952624313415, 0.4992795324265311]] [[0.9959687621865618, 0.0040102526509904635]]\n",
      "| epoch   6 step     1400 |     12 batches | lr 4.67e-05 | ms/batch 749.01 | loss 0.021268 | bpc   0.03068\n",
      "| epoch   6 step     1600 |    212 batches | lr 5.33e-05 | ms/batch 703.57 | loss 0.018733 | bpc   0.02703\n",
      "[[0.4987045119659732, 0.4987045179520277]] [[0.9960045831349756, 0.003936519788267433]]\n",
      "| epoch   7 step     1800 |    130 batches | lr 6e-05 | ms/batch 706.37 | loss 0.016752 | bpc   0.02417\n",
      "[[0.4890200741487597, 0.4890200971062654]] [[0.995830119571433, 0.003910566987572529]]\n",
      "| epoch   8 step     2000 |     52 batches | lr 6.67e-05 | ms/batch 717.21 | loss 0.016038 | bpc   0.02314\n",
      "| epoch   8 step     2200 |    252 batches | lr 7.33e-05 | ms/batch 685.74 | loss 0.015470 | bpc   0.02232\n",
      "[[0.4912568770800221, 0.4912568881969802]] [[0.9958954834861027, 0.003890487064666851]]\n",
      "| epoch   9 step     2400 |    173 batches | lr 8e-05 | ms/batch 722.82 | loss 0.015518 | bpc   0.02239\n",
      "[[0.4891726182226304, 0.48917264756087564]] [[0.9958627510771206, 0.003836020053939804]]\n",
      "| epoch  10 step     2600 |     97 batches | lr 8.67e-05 | ms/batch 721.00 | loss 0.015567 | bpc   0.02246\n",
      "[[0.4874674982961229, 0.4874674894157124]] [[0.9958073496466411, 0.0038597074323284742]]\n",
      "| epoch  11 step     2800 |     14 batches | lr 9.33e-05 | ms/batch 688.15 | loss 0.015491 | bpc   0.02235\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  11 step     3000 |    214 batches | lr 9.97e-05 | ms/batch 692.28 | loss 0.016262 | bpc   0.02346\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   1 at step     3000 | time: 2182.69s | valid loss 0.002632 | bpc   0.02346\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0] [1.0]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "[[0.4862938565986815, 0.4862938961329536]] [[0.9957792239023743, 0.0038082065010788947]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  12 step     3200 |    136 batches | lr 9.97e-05 | ms/batch 832.97 | loss 0.015304 | bpc   0.02208\n",
      "[[0.4836603111974439, 0.48366030652700587]] [[0.9957232918633134, 0.0038025901221085535]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  13 step     3400 |     59 batches | lr 9.96e-05 | ms/batch 710.62 | loss 0.014930 | bpc   0.02154\n",
      "| epoch  13 step     3600 |    259 batches | lr 9.96e-05 | ms/batch 687.40 | loss 0.016541 | bpc   0.02386\n",
      "[[0.48580938718446753, 0.48580936652929047]] [[0.9957451430930363, 0.0038556741991475074]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  14 step     3800 |    180 batches | lr 9.95e-05 | ms/batch 706.40 | loss 0.014810 | bpc   0.02137\n",
      "[[0.48178583467231817, 0.48178581513541496]] [[0.9957304616363288, 0.0037755440531926448]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  15 step     4000 |    101 batches | lr 9.95e-05 | ms/batch 725.55 | loss 0.016888 | bpc   0.02436\n",
      "[[0.4831667883691625, 0.48316681053729854]] [[0.9957407780289367, 0.003798696193446513]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  16 step     4200 |     26 batches | lr 9.94e-05 | ms/batch 719.58 | loss 0.014786 | bpc   0.02133\n",
      "| epoch  16 step     4400 |    226 batches | lr 9.93e-05 | ms/batch 697.38 | loss 0.016560 | bpc   0.02389\n",
      "[[0.4826199382152767, 0.4826199305847017]] [[0.9957002025207062, 0.0038186818002465222]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  17 step     4600 |    149 batches | lr 9.93e-05 | ms/batch 716.66 | loss 0.015551 | bpc   0.02244\n",
      "[[0.4790674079392746, 0.47906741070206915]] [[0.9956412947465697, 0.0037401171160506997]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  18 step     4800 |     73 batches | lr 9.92e-05 | ms/batch 720.77 | loss 0.016779 | bpc   0.02421\n",
      "| epoch  18 step     5000 |    273 batches | lr 9.91e-05 | ms/batch 688.43 | loss 0.014796 | bpc   0.02135\n",
      "[[0.48788288180026096, 0.4878828914700413]] [[0.9958188406562646, 0.0038178860961325255]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  19 step     5200 |    194 batches | lr 9.91e-05 | ms/batch 710.01 | loss 0.016274 | bpc   0.02348\n",
      "[[0.4823899148619966, 0.48238990815235316]] [[0.9957518986712186, 0.0037715171506268737]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  20 step     5400 |    115 batches | lr 9.9e-05 | ms/batch 718.39 | loss 0.016686 | bpc   0.02407\n",
      "[[0.4881395284927013, 0.48813955473924797]] [[0.9957568692471549, 0.003895466417685049]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  21 step     5600 |     39 batches | lr 9.89e-05 | ms/batch 709.55 | loss 0.015302 | bpc   0.02208\n",
      "| epoch  21 step     5800 |    239 batches | lr 9.89e-05 | ms/batch 673.49 | loss 0.014673 | bpc   0.02117\n",
      "[[0.48062531230134337, 0.4806253286149865]] [[0.9956718538187268, 0.003811469680590815]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  22 step     6000 |    156 batches | lr 9.88e-05 | ms/batch 716.51 | loss 0.014886 | bpc   0.02148\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   2 at step     6000 | time: 2144.89s | valid loss 0.002375 | bpc   0.02148\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0] [1.0]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "[[0.4831505832644942, 0.48315061003728743]] [[0.9957389373592211, 0.003754299099456018]]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "| epoch  23 step     6200 |     79 batches | lr 9.87e-05 | ms/batch 828.95 | loss 0.017475 | bpc   0.02521\n"
     ]
    }
   ],
   "source": [
    "!./scripts/run_trasformer_xl.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xibCj4_ewlrf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "transformer-xl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
